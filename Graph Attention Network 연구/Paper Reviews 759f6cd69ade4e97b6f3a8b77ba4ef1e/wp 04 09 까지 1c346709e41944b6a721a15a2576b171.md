# wp 04/09 까지

TOPIC: GraphSAGE
URL: https://arxiv.org/pdf/1706.02216.pdf
간략 설명: Unseen nodes, Newly added nodes에 너무나 취약한 GNN의 현주소... 더 좋은 방법이 없을까?
    (transductive —> inductive)
center node에서 random sampling 과 random walk를 통한 이웃 노드 반영.
    Appendex, Algorithm 2에서 minibatch가 만들어지는 과정을 봤을 때,
    k 가 layer인데 이게 우리가 생각하는 1hop 원이 아님을 유의
    k = K ... 1임을 유의
    Bk 는 중심노드. 중심노드의 이웃을 샘플링한 것을 Bk-1에 넣어줌
    (GCN에서는 1hop에 있는 애들 싹다 긁어모으는 방식)
이웃 노드를 반영할때 mean / max / sum / weight 등의 'degree 정보, 즉 unsupervised 방식을 채택!'
    (GCN에서는 degree만큼 가중치 내려주는 'aggregate' 방식)
learnable parameter를 통해서 저 mean/max/sum/weight 등의 정보가 inductive하게 바뀌는 방식
    (GCN에서는 그냥 DAD를 쓰는 '자신포함학습'이 끝)
Loss는 이웃을 더 좋게, negative는 더 멀게 학습