# wp 2021-04-07 까지

TOPIC: "Topology and Content Co-Alignment Graph
Convolutional Learning"
URL: https://arxiv.org/pdf/2003.12806.pdf
간략 설명: 또다른 'robust' GNN인 CoGL (견고한). Co-alignment이 핵심
real world 그래프는 사실 정확하지 않다. noisy message passing(unnecessary edge)이나 node relationship imparing(missing link) 등의 문제가 있다. 
TO-GCN처럼 Topology 자체를 수정하는 방식이 있지만 overfitting의 위험이 있다.
그래서 network topology와 node content를 distinct yet highly correlated 한, 'co-alignment' learning principle를 제안한다.
이 논문이 하고자하는것: graph structure나 node content를 아예 fixed로 보거나 아예 손을 대는 것이 아닌, 'co-alignment' 한다! (사실 별거 없다)
3가지로 분류:
- Content-aligned Graph Topology Learning
    A-bar를 사용하는데 A-bar = Feature Difference
       (말그대로 node i의 feature 에서 node j의 feature를 빼버린다)
    요런 애들 A로 두고 그냥 GCN처럼 구해서 나오는 Loss를 L-cont라고 부른다.
- Semi-supervised Graph Embedding
   A-물결을 사용하는데 이건 우리가 아는 GCN과 동일하다.
    여기서 나오는 Loss를 L-GCN이라 부른다.
- Adversarial Graph Embedding
    A-bar를 통해 나온 representation을 class 1로, A-물결을 통해 나온 representation을 class 0으로 두고 classify를 진행한다. 여기서 나오는 Loss를 L-gan이라고 부른다.
나왔던 Loss들을 다 더해주면 최종 Loss!
(여기서 GAT Citeseer가 71.0이라고 말하고 자기들은 72.4가 나왔다고 함)