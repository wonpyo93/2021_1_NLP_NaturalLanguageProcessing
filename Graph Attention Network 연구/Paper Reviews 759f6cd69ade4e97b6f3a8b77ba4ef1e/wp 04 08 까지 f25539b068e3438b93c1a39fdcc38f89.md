# wp 04/08 까지

TOPIC: Graph Attention Auto-Encoders
URL: https://arxiv.org/abs/1905.10715
간략 설명: GCN이나 GAT는 label information 기반인데 사실 real-world에선 label이 많이 없다.
그리고 GNN 모델들은 사실 semi-supervised나 supervised한 모델들이 많은데 unsupervised 한 모델은 많이 없다.
그래서 encoder / decoder를 활용하여 unsupervised model을 만듦.
encoder에서 k번의 layer를 거쳐서 H'가 만들어졌다면, 그걸 다시 백트레이싱하는 decoder를 이용해서,
결국 원래 x가 있고 그게 encoding 되고 다시 decoding 되서 predicted 한 x-hat의 차이를 보는 모델